# rename file to crab.cfg before usage
[CRAB]

jobtype = cmssw
#scheduler = glidein
###       or let crab chose one server automatically for you 
#use_server = 1
scheduler = remoteGlidein

[CMSSW]

### The data you want to access (to be found on DBS)
datasetpath=/HIMinBiasUPC/HIRun2011-PromptReco-v1/RECO
##datasetpath=/HIAllPhysics/HIRun2010-ZS-v2/RECO
##datasetpath=/HIHighPt/HIRun2011-PromptReco-v1/RECO

total_number_of_lumis   = -1
lumis_per_job            = 50	
#number_of_jobs             = 1
lumi_mask                = 182915.json

# crab: When splitting by lumi section you must specify two and only two of:
#  number_of_jobs, lumis_per_job, total_number_of_lumis

### The ParameterSet you want to use
pset=forwardanalyzer_2011data_cfg.py

### The output files (comma separated list)
output_file = ForwardTrees_skim_trackfix_clean_182915.root

[USER]
return_data = 0


### OUTPUT files INTO A SE
copy_data = 1

### if you want to copy data in a "official CMS site"
### you have to specify the name as written in
storage_element = T3_US_UMD
### the user_remote_dir will be created under the SE mountpoint
### in the case of publication this directory is not considered
### make sure the directory has proper permissions
### https://twiki.cern.ch/twiki/bin/view/CMSPublic/SWGuideCrabFaq#4_Stage_out_in_your_own_director
user_remote_dir = ForwardTrees/2011/182915/
# Setting to fix the "missing environment" error:
check_user_remote_dir=0


##  Black and White Lists management:
## By Storage
se_black_list = T0,T1
#se_white_list =

## By ComputingElement
#ce_black_list =
#ce_white_list =
